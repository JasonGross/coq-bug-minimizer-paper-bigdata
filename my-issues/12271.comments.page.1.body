cc @ppedrot 
Looks like it's another quadratic name generation issue.
I see you've filed a number of performance-related issues.  It would be nice to understand the practical impact of each if you can figure that out.  Or better yet, describe their relative priorities at some point based on user impact.  Not all performance issues are necessarily worth fixing.
Indeed, I'm working on a systematic survey of this with @achlipala and @andres-erbsen , and hope to have some results / paper / descriptions to share within the next couple weeks/months.  Though I believe the overhead of name-generation in Coq is worth fixing.  It should be possible to do all operations on names in time that is at most logarithmic in the size, and I think it's important to implement this (and to have it be accessible in Ltac2, also).
I'll be interested to read your results when they're available.  I'd appreciate it if you'd email me then.  Indeed, if you like, I"ll proofread it.

Separately, I would love to understand what drives maximum memory use.  Seems like it should be roughly:

(# of steps in the open proof) * (average size of the proof at each step) + (total sizes of all closed proofs)

IIRC Adam mentioned runs that needed almost 32GB to complete.  Hard to see how Coq would use that much memory.  I recall there was a major fast memory leak that someone, maybe you, fixed about a year ago.  Not sure it's still an issue.  Would be interesting to identify the drivers of memory use and suggest improvements.  Also, I don't have a good feel for the range of numbers for my rough formula that are reached in practice or are common.

Once the drivers for memory use are identified, it should be possible to create a command or two to compute the exact amount used for various purposes.  I also wonder if some gigantic proofs might be optimized to make them much smaller.


I have indeed had individual Coq sessions go over 32 GB of memory use (it at least used to be quite easy to do with a long enough proof script using a lot of automation), but more commonly the scaling challenges come from several Coq sessions at once via a parallel build.
The [old fiat-crypto pipeline (branch sp2019latest)](https://github.com/mit-plv/fiat-crypto/tree/sp2019latest), which I believe still builds with Coq master, contains an example of Coq memory usage growing exponentially with input size:
![mem (ko) vs  nlimbs](https://user-images.githubusercontent.com/396076/84092554-b7787e00-a9c5-11ea-9777-9cc0cbbbace1.png)
I don't have a machine with more than 60 GB of RAM, so I stopped it after it hit 40 GB, but we have examples up to n limbs = 25.  These are the files matching the globs `src/Specific/montgomery*/femul.v`.  Each folder ends with something like `8limbs` or `25limbs`; this is the `nlimbs` number.  I did these tests with Coq 8.8.0, I believe (the last version that generates correct output for this pipeline; there were incompatible changes to notation printing in 8.9).  So it's possible that this is a bug that has since been fixed, but I'm dubious.  Note that the number of steps in the proof does not drastically change as you change nlimbs (I suspect in fact it does not change at all).  The types grow quadratically as a function of nlimbs, but very slowly.  We're synthesizing an AST, and the number of lines of code in the AST as a function of nlimbs is:
![nlines vs  nlimbs](https://user-images.githubusercontent.com/396076/84093432-353d8900-a9c8-11ea-8cd8-b83c80d040e5.png)
which seems like it should be well within Coq's ability to handle.

If you can track down the memory usage in this example, I'd be pretty excited to know where it comes from.

Note that the time taken to compile these files is also exponential in nlimbs:
![time (s) vs nlimbs](https://user-images.githubusercontent.com/396076/84093053-2a362900-a9c7-11ea-80c6-6b55e4239d3e.png)
(I'd also love to know where this comes from)
Btw, @jfehrle , if you plan to track this down, the fastest file that uses ~10 GB RAM is `src/Specific/montgomery32_2e165m25_6limbs/femul.vo` which builds for me in about 7.5 minutes and takes 10,212,660 ko RAM.  The stats for all files are available [here](https://github.com/mit-plv/fiat-crypto/blob/sp2019latest/time-of-build-after-pretty.log).
It's tempting--it seems like a fun problem that may identify significant opportunities for improvement.  I'll take a quick look now.

Is there another file that takes less time to run that still shows the problem?
I'm currently working on making it build on master (turns out it only builds on 8.11).  https://github.com/mit-plv/fiat-crypto/pull/812 should fix this.

The first file over 5 GB is `src/Specific/montgomery32_2e152m17_5limbs/femul.vo` at 3m57.47s , 5258312 ko.  I think this is probably the first one that stands out from the rest.  The first file over 4 GB is only about 4 seconds faster, and there are a lot of files that take over 3 GB.
Btw, my first guess, knowing nothing about what's going on internally, is that kernel conversion is taking some unfortunate path and the intermediate terms it's generating in the course of doing conversion are blowing up.
On master (I'm using 831e901a8b796c3f2e7cec7f2b5d8adae4dfbea3), things are somewhat better than on 8.8, but not drastically so:
```
src/Specific/montgomery32_2e152m17_5limbs/femul.vo (real: 211.43, user: 209.86, sys: 1.56, mem: 3990152 ko)
src/Specific/montgomery32_2e165m25_6limbs/femul.vo (real: 436.08, user: 433.29, sys: 2.78, mem: 7368456 ko)
```

Btw, the timing breakdown for subtactics:
In src/Specific/montgomery32_2e152m17_5limbs/femul.v:
```
total time:    136.195s

 tactic                                   local  total   calls       max
────────────────────────────────────────┴──────┴──────┴───────┴─────────┘
─synthesize_mul ------------------------   0.0% 100.0%       0  136.195s
─synthesize_carry_mul ------------------   0.0% 100.0%       0  136.195s
─synthesize_2arg_choice_with_carry -----   0.0% 100.0%       0  136.195s
─synthesize_narg_choice_gen ------------   0.0% 100.0%       0  136.195s
─Pipeline.refine_reflectively_gen ------   0.0%  99.1%       1  134.994s
─ReflectiveTactics.do_reflective_pipelin   0.0%  98.8%       1  134.626s
─ReflectiveTactics.solve_side_conditions   0.0%  98.7%       1  134.466s
─ReflectiveTactics.do_reify ------------   0.0%  87.5%       1  119.157s
─Reify.Reify_rhs_gen -------------------   0.4%  87.2%       1  118.813s
─Reify ---------------------------------   0.0%  82.3%       0  112.079s
─Compilers.Reify.Reify -----------------   0.1%  82.3%       0  112.076s
─Compilers.Reify.Reify' ----------------   0.0%  82.2%       0  111.958s
─Reify.do_reify_abs_goal ---------------   0.0%  82.2%       2  111.947s
─Reify.reify_abs -----------------------  82.1%  82.1%       0  111.828s
─ReflectiveTactics.solve_post_reified_si   0.0%  11.2%       1   15.309s
─UnifyAbstractReflexivity.unify_transfor   0.0%  10.1%       7    3.143s
─abstract exact_no_check eq_refl -------   8.9%   8.9%       8    2.422s

 tactic                                   local  total   calls       max
────────────────────────────────────────┴──────┴──────┴───────┴─────────┘
─synthesize_mul ------------------------   0.0% 100.0%       0  136.195s
└synthesize_carry_mul ------------------   0.0% 100.0%       0  136.195s
└synthesize_2arg_choice_with_carry -----   0.0% 100.0%       0  136.195s
└synthesize_narg_choice_gen ------------   0.0% 100.0%       0  136.195s
└Pipeline.refine_reflectively_gen ------   0.0%  99.1%       1  134.994s
└ReflectiveTactics.do_reflective_pipelin   0.0%  98.8%       1  134.626s
└ReflectiveTactics.solve_side_conditions   0.0%  98.7%       1  134.466s
 ├─ReflectiveTactics.do_reify ----------   0.0%  87.5%       1  119.157s
 │└Reify.Reify_rhs_gen -----------------   0.4%  87.2%       1  118.813s
 │└Reify -------------------------------   0.0%  82.3%       0  112.079s
 │└Compilers.Reify.Reify ---------------   0.1%  82.3%       0  112.076s
 │└Compilers.Reify.Reify' --------------   0.0%  82.2%       0  111.958s
 │└Reify.do_reify_abs_goal -------------   0.0%  82.2%       2  111.947s
 │└Reify.reify_abs ---------------------  82.1%  82.1%       0  111.828s
 └─ReflectiveTactics.solve_post_reified_   0.0%  11.2%       1   15.309s
  └UnifyAbstractReflexivity.unify_transf   0.0%  10.1%       7    3.143s
  └abstract exact_no_check eq_refl -----   8.3%   8.3%       7    2.422s
```
In src/Specific/montgomery32_2e165m25_6limbs/femul.v:
```
total time:    321.404s

 tactic                                   local  total   calls       max
────────────────────────────────────────┴──────┴──────┴───────┴─────────┘
─synthesize_mul ------------------------   0.0% 100.0%       0  321.404s
─synthesize_carry_mul ------------------   0.0% 100.0%       0  321.404s
─synthesize_2arg_choice_with_carry -----   0.0% 100.0%       0  321.404s
─synthesize_narg_choice_gen ------------   0.0% 100.0%       0  321.404s
─Pipeline.refine_reflectively_gen ------   0.0%  99.5%       1  319.882s
─ReflectiveTactics.do_reflective_pipelin   0.0%  99.4%       1  319.385s
─ReflectiveTactics.solve_side_conditions   0.0%  99.3%       1  319.137s
─ReflectiveTactics.do_reify ------------   0.0%  92.6%       1  297.487s
─Reify.Reify_rhs_gen -------------------   0.2%  92.4%       1  297.068s
─Reify ---------------------------------   0.0%  89.4%       0  287.464s
─Compilers.Reify.Reify -----------------   0.1%  89.4%       0  287.460s
─Compilers.Reify.Reify' ----------------   0.0%  89.4%       0  287.288s
─Reify.do_reify_abs_goal ---------------   0.0%  89.4%       2  287.271s
─Reify.reify_abs -----------------------  89.3%  89.3%       0  287.091s
─ReflectiveTactics.solve_post_reified_si   0.0%   6.7%       1   21.649s
─UnifyAbstractReflexivity.unify_transfor   0.0%   6.1%       7    4.371s
─abstract exact_no_check eq_refl -------   5.3%   5.3%       8    3.354s

 tactic                                   local  total   calls       max
────────────────────────────────────────┴──────┴──────┴───────┴─────────┘
─synthesize_mul ------------------------   0.0% 100.0%       0  321.404s
└synthesize_carry_mul ------------------   0.0% 100.0%       0  321.404s
└synthesize_2arg_choice_with_carry -----   0.0% 100.0%       0  321.404s
└synthesize_narg_choice_gen ------------   0.0% 100.0%       0  321.404s
└Pipeline.refine_reflectively_gen ------   0.0%  99.5%       1  319.882s
└ReflectiveTactics.do_reflective_pipelin   0.0%  99.4%       1  319.385s
└ReflectiveTactics.solve_side_conditions   0.0%  99.3%       1  319.137s
 ├─ReflectiveTactics.do_reify ----------   0.0%  92.6%       1  297.487s
 │└Reify.Reify_rhs_gen -----------------   0.2%  92.4%       1  297.068s
 │└Reify -------------------------------   0.0%  89.4%       0  287.464s
 │└Compilers.Reify.Reify ---------------   0.1%  89.4%       0  287.460s
 │└Compilers.Reify.Reify' --------------   0.0%  89.4%       0  287.288s
 │└Reify.do_reify_abs_goal -------------   0.0%  89.4%       2  287.271s
 │└Reify.reify_abs ---------------------  89.3%  89.3%       0  287.091s
 └─ReflectiveTactics.solve_post_reified_   0.0%   6.7%       1   21.649s
  └UnifyAbstractReflexivity.unify_transf   0.0%   6.1%       7    4.371s
  └abstract exact_no_check eq_refl -----   4.9%   4.9%       7    3.354s
```

So my guess looking at this is that the time and memory is spent in typeclass resolution, possibly in allocating large evar contexts/substitutions?

(Btw, we should plausibly move this discussion to another issue...)
Moving discussion to #12487
