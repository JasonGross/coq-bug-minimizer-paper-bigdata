{"id":551148064,"status":"success","stage":"stage-4","name":"library:ci-corn","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.887Z","started_at":"2020-05-13T19:24:09.122Z","finished_at":"2020-05-13T19:58:17.461Z","duration":2048.339264,"queued_duration":0.621483,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148064","artifacts":[{"file_type":"trace","size":448242,"filename":"job.log","file_format":null}],"runner":{"id":44949,"description":"shared-runners-manager-4.gitlab.com","ip_address":"13.37.237.197","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148063,"status":"success","stage":"stage-4","name":"library:ci-fiat_crypto","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.853Z","started_at":"2020-05-13T19:25:01.196Z","finished_at":"2020-05-13T21:43:33.401Z","duration":8312.205084,"queued_duration":0.585023,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148063","artifacts":[{"file_type":"trace","size":2514694,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":null,"tag_list":[]}
{"id":551148062,"status":"success","stage":"stage-3","name":"plugin:ci-metacoq","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.813Z","started_at":"2020-05-13T18:58:14.706Z","finished_at":"2020-05-13T19:26:42.689Z","duration":1707.982451,"queued_duration":0.758315,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148062","artifacts":[{"file_type":"trace","size":298269,"filename":"job.log","file_format":null}],"runner":{"id":380986,"description":"shared-runners-manager-5.gitlab.com","ip_address":"34.74.209.140","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148061,"status":"success","stage":"stage-3","name":"library:ci-vst","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.774Z","started_at":"2020-05-13T19:18:40.738Z","finished_at":"2020-05-13T20:09:24.621Z","duration":3043.883784,"queued_duration":1.009069,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148061","artifacts":[{"file_type":"trace","size":526843,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":null,"tag_list":[]}
{"id":551148060,"status":"success","stage":"stage-3","name":"library:ci-math_classes","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.746Z","started_at":"2020-05-13T19:17:53.209Z","finished_at":"2020-05-13T19:24:08.338Z","duration":375.128707,"queued_duration":0.335873,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148060","artifacts":[{"file_type":"trace","size":209718,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":null,"tag_list":[]}
{"id":551148059,"status":"success","stage":"stage-3","name":"library:ci-coqprime","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.719Z","started_at":"2020-05-13T19:17:52.729Z","finished_at":"2020-05-13T19:22:58.800Z","duration":306.070611,"queued_duration":0.695799,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148059","artifacts":[{"file_type":"trace","size":134738,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":null,"tag_list":[]}
{"id":551148058,"status":"success","stage":"stage-3","name":"library:ci-color","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.694Z","started_at":"2020-05-13T19:17:51.899Z","finished_at":"2020-05-13T19:34:46.332Z","duration":1014.432647,"queued_duration":0.467639,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148058","artifacts":[{"file_type":"trace","size":631620,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":null,"tag_list":[]}
{"id":551148057,"status":"success","stage":"stage-2","name":"plugin:ci-rewriter","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.660Z","started_at":"2020-05-13T19:11:15.649Z","finished_at":"2020-05-13T19:25:00.457Z","duration":824.807697,"queued_duration":2.223921,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148057","artifacts":[{"file_type":"trace","size":224596,"filename":"job.log","file_format":null}],"runner":{"id":380987,"description":"shared-runners-manager-6.gitlab.com","ip_address":"34.74.239.13","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148056,"status":"success","stage":"stage-2","name":"plugin:ci-relation_algebra","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.639Z","started_at":"2020-05-13T18:51:56.930Z","finished_at":"2020-05-13T18:57:47.131Z","duration":350.201572,"queued_duration":1.849317,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148056","artifacts":[{"file_type":"trace","size":252864,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":null,"tag_list":[]}
{"id":551148055,"status":"success","stage":"stage-2","name":"plugin:ci-reduction_effects","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.622Z","started_at":"2020-05-13T18:51:56.874Z","finished_at":"2020-05-13T18:53:38.349Z","duration":101.475327,"queued_duration":1.871228,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148055","artifacts":[{"file_type":"trace","size":64780,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":null,"tag_list":[]}
{"id":551148054,"status":"success","stage":"stage-2","name":"plugin:ci-quickchick","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.599Z","started_at":"2020-05-13T19:11:15.497Z","finished_at":"2020-05-13T19:18:13.679Z","duration":418.181757,"queued_duration":2.142389,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148054","artifacts":[{"file_type":"trace","size":292457,"filename":"job.log","file_format":null}],"runner":{"id":380986,"description":"shared-runners-manager-5.gitlab.com","ip_address":"34.74.209.140","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148052,"status":"success","stage":"stage-2","name":"plugin:ci-perennial","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.577Z","started_at":"2020-05-13T19:11:15.454Z","finished_at":"2020-05-13T20:17:02.398Z","duration":3946.943963,"queued_duration":2.151092,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148052","artifacts":[{"file_type":"trace","size":42582,"filename":"job.log","file_format":null}],"runner":{"id":44949,"description":"shared-runners-manager-4.gitlab.com","ip_address":"13.37.237.197","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148051,"status":"success","stage":"stage-2","name":"plugin:ci-paramcoq","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.556Z","started_at":"2020-05-13T18:51:56.831Z","finished_at":"2020-05-13T18:55:25.592Z","duration":208.761446,"queued_duration":1.892208,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148051","artifacts":[{"file_type":"trace","size":86319,"filename":"job.log","file_format":null}],"runner":{"id":44028,"description":"shared-runners-manager-3.gitlab.com","ip_address":"35.196.21.178","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148050,"status":"success","stage":"stage-2","name":"plugin:ci-mtac2","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.535Z","started_at":"2020-05-13T18:51:56.770Z","finished_at":"2020-05-13T18:57:14.717Z","duration":317.946413,"queued_duration":1.893186,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148050","artifacts":[{"file_type":"trace","size":160952,"filename":"job.log","file_format":null}],"runner":{"id":44028,"description":"shared-runners-manager-3.gitlab.com","ip_address":"35.196.21.178","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148049,"status":"success","stage":"stage-2","name":"plugin:ci-fiat_parsers","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.516Z","started_at":"2020-05-13T18:51:56.504Z","finished_at":"2020-05-13T19:08:14.309Z","duration":977.804894,"queued_duration":1.700221,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148049","artifacts":[{"file_type":"trace","size":852213,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":null,"tag_list":[]}
{"id":551148048,"status":"success","stage":"stage-2","name":"plugin:ci-equations","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.499Z","started_at":"2020-05-13T18:51:56.461Z","finished_at":"2020-05-13T18:58:13.787Z","duration":377.326427,"queued_duration":1.734072,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148048","artifacts":[{"file_type":"trace","size":168301,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":null,"tag_list":[]}
{"id":551148047,"status":"success","stage":"stage-2","name":"plugin:ci-elpi","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.482Z","started_at":"2020-05-13T18:51:56.389Z","finished_at":"2020-05-13T18:59:18.048Z","duration":441.658562,"queued_duration":1.730638,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148047","artifacts":[{"file_type":"trace","size":348392,"filename":"job.log","file_format":null}],"runner":{"id":380986,"description":"shared-runners-manager-5.gitlab.com","ip_address":"34.74.209.140","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148046,"status":"success","stage":"stage-2","name":"plugin:ci-coqhammer","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.460Z","started_at":"2020-05-13T18:51:56.340Z","finished_at":"2020-05-13T18:55:23.994Z","duration":207.654171,"queued_duration":1.755309,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148046","artifacts":[{"file_type":"trace","size":48254,"filename":"job.log","file_format":null}],"runner":{"id":44949,"description":"shared-runners-manager-4.gitlab.com","ip_address":"13.37.237.197","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148045,"status":"success","stage":"stage-2","name":"plugin:ci-coq_dpdgraph","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.434Z","started_at":"2020-05-13T18:51:56.249Z","finished_at":"2020-05-13T18:55:17.095Z","duration":200.846137,"queued_duration":1.756382,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148045","artifacts":[{"file_type":"trace","size":47227,"filename":"job.log","file_format":null}],"runner":{"id":380986,"description":"shared-runners-manager-5.gitlab.com","ip_address":"34.74.209.140","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148044,"status":"success","stage":"stage-2","name":"plugin:ci-bignums","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.412Z","started_at":"2020-05-13T19:11:15.396Z","finished_at":"2020-05-13T19:17:49.589Z","duration":394.193027,"queued_duration":2.1483,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148044","artifacts":[{"file_type":"trace","size":593833,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":null,"tag_list":[]}
{"id":551148043,"status":"success","stage":"stage-2","name":"plugin:ci-aac_tactics","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.390Z","started_at":"2020-05-13T18:51:56.206Z","finished_at":"2020-05-13T18:55:23.332Z","duration":207.125844,"queued_duration":1.79429,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148043","artifacts":[{"file_type":"trace","size":55556,"filename":"job.log","file_format":null}],"runner":{"id":380987,"description":"shared-runners-manager-6.gitlab.com","ip_address":"34.74.239.13","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148042,"status":"success","stage":"stage-2","name":"library:ci-verdi_raft","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.364Z","started_at":"2020-05-13T19:11:15.001Z","finished_at":"2020-05-13T19:34:21.898Z","duration":1386.897474,"queued_duration":1.806778,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148042","artifacts":[{"file_type":"trace","size":341887,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":null,"tag_list":[]}
{"id":551148041,"status":"success","stage":"stage-2","name":"library:ci-unimath","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.327Z","started_at":"2020-05-13T19:11:14.856Z","finished_at":"2020-05-13T20:06:23.768Z","duration":3308.912029,"queued_duration":1.712768,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148041","artifacts":[{"file_type":"trace","size":256663,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":null,"tag_list":[]}
{"id":551148040,"status":"success","stage":"stage-2","name":"library:ci-tlc","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.304Z","started_at":"2020-05-13T18:51:56.056Z","finished_at":"2020-05-13T18:55:33.801Z","duration":217.7455,"queued_duration":1.715034,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148040","artifacts":[{"file_type":"trace","size":187043,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":null,"tag_list":[]}
{"id":551148038,"status":"success","stage":"stage-2","name":"library:ci-stdlib2","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.287Z","started_at":"2020-05-13T19:11:14.578Z","finished_at":"2020-05-13T19:16:20.979Z","duration":306.401753,"queued_duration":1.488405,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148038","artifacts":[{"file_type":"trace","size":63535,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":null,"tag_list":[]}
{"id":551148037,"status":"failed","stage":"stage-2","name":"library:ci-sf","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.268Z","started_at":"2020-05-13T18:51:56.011Z","finished_at":"2020-05-13T18:54:49.231Z","duration":173.22027,"queued_duration":1.76882,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"failure_reason":"script_failure","web_url":"https://gitlab.com/coq/coq/-/jobs/551148037","artifacts":[{"file_type":"trace","size":554046,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":null,"tag_list":[]}
{"id":551148036,"status":"success","stage":"stage-2","name":"library:ci-mathcomp","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.253Z","started_at":"2020-05-13T19:11:14.442Z","finished_at":"2020-05-13T20:26:16.581Z","duration":4502.139048,"queued_duration":1.410557,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148036","artifacts":[{"file_type":"trace","size":451727,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":null,"tag_list":[]}
{"id":551148035,"status":"success","stage":"stage-2","name":"library:ci-lambda_rust","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.234Z","started_at":"2020-05-13T19:11:14.348Z","finished_at":"2020-05-13T20:02:30.119Z","duration":3075.770567,"queued_duration":1.371182,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148035","artifacts":[{"file_type":"trace","size":332631,"filename":"job.log","file_format":null}],"runner":{"id":380987,"description":"shared-runners-manager-6.gitlab.com","ip_address":"34.74.239.13","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148034,"status":"success","stage":"stage-2","name":"library:ci-hott","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.215Z","started_at":"2020-05-13T18:51:55.742Z","finished_at":"2020-05-13T19:02:36.588Z","duration":640.845834,"queued_duration":1.566771,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148034","artifacts":[{"file_type":"trace","size":133658,"filename":"job.log","file_format":null}],"runner":{"id":44028,"description":"shared-runners-manager-3.gitlab.com","ip_address":"35.196.21.178","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148033,"status":"success","stage":"stage-2","name":"library:ci-geocoq","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.195Z","started_at":"2020-05-13T19:11:14.307Z","finished_at":"2020-05-13T19:48:47.992Z","duration":2253.684552,"queued_duration":1.383872,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148033","artifacts":[{"file_type":"trace","size":503929,"filename":"job.log","file_format":null}],"runner":{"id":380987,"description":"shared-runners-manager-6.gitlab.com","ip_address":"34.74.239.13","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148032,"status":"success","stage":"stage-2","name":"library:ci-flocq","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.178Z","started_at":"2020-05-13T19:11:14.265Z","finished_at":"2020-05-13T19:18:39.581Z","duration":445.316619,"queued_duration":1.407933,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148032","artifacts":[{"file_type":"trace","size":126885,"filename":"job.log","file_format":null}],"runner":{"id":44949,"description":"shared-runners-manager-4.gitlab.com","ip_address":"13.37.237.197","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148031,"status":"success","stage":"stage-2","name":"library:ci-fcsl_pcm","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.157Z","started_at":"2020-05-13T18:51:55.684Z","finished_at":"2020-05-13T18:56:41.151Z","duration":285.467069,"queued_duration":1.584881,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148031","artifacts":[{"file_type":"trace","size":150434,"filename":"job.log","file_format":null}],"runner":{"id":44949,"description":"shared-runners-manager-4.gitlab.com","ip_address":"13.37.237.197","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148030,"status":"success","stage":"stage-2","name":"library:ci-cross_crypto","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.139Z","started_at":"2020-05-13T18:51:55.637Z","finished_at":"2020-05-13T19:24:18.104Z","duration":1942.467097,"queued_duration":1.609331,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148030","artifacts":[{"file_type":"trace","size":394557,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":null,"tag_list":[]}
{"id":551148029,"status":"success","stage":"stage-2","name":"library:ci-coquelicot","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.117Z","started_at":"2020-05-13T18:51:55.563Z","finished_at":"2020-05-13T18:57:06.041Z","duration":310.478173,"queued_duration":1.595326,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148029","artifacts":[{"file_type":"trace","size":218585,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":null,"tag_list":[]}
{"id":551148028,"status":"success","stage":"stage-2","name":"library:ci-coq_tools","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.098Z","started_at":"2020-05-13T18:51:55.514Z","finished_at":"2020-05-13T18:59:30.752Z","duration":455.238574,"queued_duration":1.608432,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148028","artifacts":[{"file_type":"trace","size":46740,"filename":"job.log","file_format":null}],"runner":{"id":44028,"description":"shared-runners-manager-3.gitlab.com","ip_address":"35.196.21.178","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148027,"status":"success","stage":"stage-2","name":"library:ci-compcert","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.077Z","started_at":"2020-05-13T19:11:14.141Z","finished_at":"2020-05-13T19:31:55.161Z","duration":1241.020666,"queued_duration":1.34963,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148027","artifacts":[{"file_type":"trace","size":4194361,"filename":"job.log","file_format":null}],"runner":{"id":44028,"description":"shared-runners-manager-3.gitlab.com","ip_address":"35.196.21.178","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148026,"status":"success","stage":"stage-2","name":"library:ci-bedrock2","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.059Z","started_at":"2020-05-13T19:11:14.092Z","finished_at":"2020-05-13T21:06:04.186Z","duration":6890.094409,"queued_duration":1.361917,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148026","artifacts":[{"file_type":"trace","size":513187,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":null,"tag_list":[]}
{"id":551148025,"status":"success","stage":"stage-2","name":"library:ci-bbv","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.040Z","started_at":"2020-05-13T18:51:55.384Z","finished_at":"2020-05-13T18:55:50.758Z","duration":235.374714,"queued_duration":1.538406,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148025","artifacts":[{"file_type":"trace","size":119611,"filename":"job.log","file_format":null}],"runner":{"id":44949,"description":"shared-runners-manager-4.gitlab.com","ip_address":"13.37.237.197","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148024,"status":"success","stage":"stage-2","name":"library:ci-argosy","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:22.019Z","started_at":"2020-05-13T18:51:55.202Z","finished_at":"2020-05-13T18:56:16.740Z","duration":261.537837,"queued_duration":1.429715,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148024","artifacts":[{"file_type":"trace","size":144345,"filename":"job.log","file_format":null}],"runner":{"id":380986,"description":"shared-runners-manager-5.gitlab.com","ip_address":"34.74.209.140","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148023,"status":"success","stage":"stage-2","name":"validate:quick","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:21.997Z","started_at":"2020-05-13T19:00:12.151Z","finished_at":"2020-05-13T19:04:58.363Z","duration":286.211552,"queued_duration":0.706522,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148023","artifacts":[{"file_type":"trace","size":73334,"filename":"job.log","file_format":null}],"runner":{"id":44028,"description":"shared-runners-manager-3.gitlab.com","ip_address":"35.196.21.178","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":"2020-07-12T19:04:57.000Z","tag_list":[]}
{"id":551148022,"status":"success","stage":"stage-2","name":"validate:edge+flambda","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:21.969Z","started_at":"2020-05-13T19:11:13.989Z","finished_at":"2020-05-13T19:15:45.947Z","duration":271.958137,"queued_duration":1.327424,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148022","artifacts":[{"file_type":"trace","size":112663,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":"2020-07-12T19:15:43.062Z","tag_list":[]}
{"id":551148021,"status":"success","stage":"stage-2","name":"validate:base+32bit","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:21.947Z","started_at":"2020-05-13T18:58:11.538Z","finished_at":"2020-05-13T19:02:59.370Z","duration":287.832129,"queued_duration":0.749461,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148021","artifacts":[{"file_type":"trace","size":71710,"filename":"job.log","file_format":null}],"runner":{"id":44949,"description":"shared-runners-manager-4.gitlab.com","ip_address":"13.37.237.197","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":"2020-07-12T19:02:57.984Z","tag_list":[]}
{"id":551148020,"status":"success","stage":"stage-2","name":"validate:base","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:21.925Z","started_at":"2020-05-13T18:51:55.133Z","finished_at":"2020-05-13T18:56:46.605Z","duration":291.472047,"queued_duration":1.424927,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148020","artifacts":[{"file_type":"trace","size":73269,"filename":"job.log","file_format":null}],"runner":{"id":380987,"description":"shared-runners-manager-6.gitlab.com","ip_address":"34.74.239.13","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":"2020-07-12T18:56:45.221Z","tag_list":[]}
{"id":551148019,"status":"failed","stage":"stage-2","name":"test-suite:base+async","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":true,"created_at":"2020-05-13T18:41:21.907Z","started_at":"2020-05-13T18:51:55.004Z","finished_at":"2020-05-13T19:31:12.927Z","duration":2357.923247,"queued_duration":1.354112,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"failure_reason":"script_failure","web_url":"https://gitlab.com/coq/coq/-/jobs/551148019","artifacts":[{"file_type":"trace","size":131784,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":null,"tag_list":[]}
{"id":551148018,"status":"success","stage":"stage-2","name":"test-suite:edge:dune:dev","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:21.893Z","started_at":"2020-05-13T19:03:20.406Z","finished_at":"2020-05-13T19:28:54.724Z","duration":1534.318174,"queued_duration":0.859892,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148018","artifacts":[{"file_type":"trace","size":100543,"filename":"job.log","file_format":null}],"runner":{"id":44028,"description":"shared-runners-manager-3.gitlab.com","ip_address":"35.196.21.178","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148017,"status":"success","stage":"stage-2","name":"test-suite:edge+flambda","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:21.875Z","started_at":"2020-05-13T19:11:13.697Z","finished_at":"2020-05-13T19:29:08.993Z","duration":1075.295225,"queued_duration":1.09079,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148017","artifacts":[{"file_type":"trace","size":124709,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":null,"tag_list":[]}
{"id":551148016,"status":"success","stage":"stage-2","name":"test-suite:base+32bit","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:21.855Z","started_at":"2020-05-13T18:58:11.226Z","finished_at":"2020-05-13T19:08:20.224Z","duration":608.998688,"queued_duration":0.486951,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148016","artifacts":[{"file_type":"trace","size":103425,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":null,"tag_list":[]}
{"id":551148015,"status":"success","stage":"stage-2","name":"test-suite:base","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:21.838Z","started_at":"2020-05-13T18:51:54.600Z","finished_at":"2020-05-13T19:12:06.493Z","duration":1211.893201,"queued_duration":1.011107,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148015","artifacts":[{"file_type":"trace","size":100426,"filename":"job.log","file_format":null}],"runner":{"id":44028,"description":"shared-runners-manager-3.gitlab.com","ip_address":"35.196.21.178","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148014,"status":"success","stage":"stage-2","name":"doc:ml-api:odoc","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:21.820Z","started_at":"2020-05-13T19:03:20.328Z","finished_at":"2020-05-13T19:07:56.460Z","duration":276.132281,"queued_duration":0.839069,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148014","artifacts":[{"file_type":"trace","size":81111,"filename":"job.log","file_format":null}],"runner":{"id":44028,"description":"shared-runners-manager-3.gitlab.com","ip_address":"35.196.21.178","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":"2020-07-12T19:07:54.203Z","tag_list":[]}
{"id":551148013,"status":"success","stage":"stage-2","name":"doc:stdlib:dune","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:21.799Z","started_at":"2020-05-13T19:03:20.278Z","finished_at":"2020-05-13T19:07:56.208Z","duration":275.930024,"queued_duration":0.84026,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148013","artifacts":[{"file_type":"trace","size":82527,"filename":"job.log","file_format":null}],"runner":{"id":44949,"description":"shared-runners-manager-4.gitlab.com","ip_address":"13.37.237.197","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":"2020-07-12T19:07:54.549Z","tag_list":[]}
{"id":551148012,"status":"success","stage":"stage-2","name":"doc:refman-pdf:dune","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:21.777Z","started_at":"2020-05-13T19:03:20.059Z","finished_at":"2020-05-13T19:12:05.501Z","duration":525.442741,"queued_duration":0.676697,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148012","artifacts":[{"file_type":"trace","size":28371,"filename":"job.log","file_format":null}],"runner":{"id":44949,"description":"shared-runners-manager-4.gitlab.com","ip_address":"13.37.237.197","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":"2020-07-12T19:12:03.829Z","tag_list":[]}
{"id":551148011,"status":"success","stage":"stage-2","name":"doc:refman:dune","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:21.758Z","started_at":"2020-05-13T19:03:19.967Z","finished_at":"2020-05-13T19:09:02.343Z","duration":342.375705,"queued_duration":0.63943,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148011","artifacts":[{"file_type":"trace","size":56925,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":"2020-07-12T19:08:59.832Z","tag_list":[]}
{"id":551148010,"status":"success","stage":"stage-2","name":"doc:refman","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:21.738Z","started_at":"2020-05-13T18:51:53.643Z","finished_at":"2020-05-13T18:57:31.110Z","duration":337.467583,"queued_duration":0.125923,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148010","artifacts":[{"file_type":"trace","size":1739929,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":"2020-07-12T18:57:28.579Z","tag_list":[]}
{"id":551148009,"status":"success","stage":"stage-1","name":"plugin:plugin-tutorial","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:21.689Z","started_at":"2020-05-13T18:41:25.525Z","finished_at":"2020-05-13T18:45:42.866Z","duration":257.340542,"queued_duration":1.963242,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148009","artifacts":[{"file_type":"trace","size":62432,"filename":"job.log","file_format":null}],"runner":{"id":380987,"description":"shared-runners-manager-6.gitlab.com","ip_address":"34.74.239.13","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148008,"status":"success","stage":"stage-1","name":"test-suite:edge+4.11+trunk+dune","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":true,"created_at":"2020-05-13T18:41:21.672Z","started_at":"2020-05-13T18:41:25.434Z","finished_at":"2020-05-13T19:26:59.293Z","duration":2733.858549,"queued_duration":1.893791,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148008","artifacts":[{"file_type":"trace","size":102853,"filename":"job.log","file_format":null}],"runner":{"id":380987,"description":"shared-runners-manager-6.gitlab.com","ip_address":"34.74.239.13","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":"2020-05-27T19:26:57.461Z","tag_list":[]}
{"id":551148007,"status":"success","stage":"stage-1","name":"pkg:nix","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:21.654Z","started_at":"2020-05-13T18:41:25.384Z","finished_at":"2020-05-13T19:25:41.869Z","duration":2656.485142,"queued_duration":1.869389,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148007","artifacts":[{"file_type":"trace","size":585319,"filename":"job.log","file_format":null}],"runner":{"id":44028,"description":"shared-runners-manager-3.gitlab.com","ip_address":"35.196.21.178","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148006,"status":"success","stage":"stage-1","name":"pkg:opam","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:21.634Z","started_at":"2020-05-13T18:41:24.949Z","finished_at":"2020-05-13T19:08:28.205Z","duration":1623.256799,"queued_duration":1.457896,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148006","artifacts":[{"file_type":"trace","size":24398,"filename":"job.log","file_format":null}],"runner":{"id":380986,"description":"shared-runners-manager-5.gitlab.com","ip_address":"34.74.209.140","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148004,"status":"success","stage":"stage-1","name":"lint","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:21.613Z","started_at":"2020-05-13T18:41:24.874Z","finished_at":"2020-05-13T18:46:46.419Z","duration":321.545321,"queued_duration":1.407539,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148004","artifacts":[{"file_type":"trace","size":41016,"filename":"job.log","file_format":null}],"runner":{"id":380987,"description":"shared-runners-manager-6.gitlab.com","ip_address":"34.74.239.13","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":null,"tag_list":[]}
{"id":551148003,"status":"success","stage":"stage-1","name":"windows64","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:21.588Z","started_at":"2020-05-13T18:41:23.858Z","finished_at":"2020-05-13T19:38:01.395Z","duration":3397.537531,"queued_duration":0.414942,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148003","artifacts":[{"file_type":"trace","size":241523,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":"2020-05-20T19:38:00.148Z","tag_list":["windows-inria"]}
{"id":551148002,"status":"success","stage":"stage-1","name":"build:quick","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":true,"created_at":"2020-05-13T18:41:21.571Z","started_at":"2020-05-13T18:41:24.570Z","finished_at":"2020-05-13T19:00:11.238Z","duration":1126.66829,"queued_duration":1.154953,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148002","artifacts":[{"file_type":"trace","size":200751,"filename":"job.log","file_format":null}],"runner":{"id":380987,"description":"shared-runners-manager-6.gitlab.com","ip_address":"34.74.239.13","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":"2020-05-20T19:00:09.811Z","tag_list":[]}
{"id":551148001,"status":"success","stage":"stage-1","name":"build:base+async","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":true,"created_at":"2020-05-13T18:41:21.541Z","started_at":"2020-05-13T18:41:24.517Z","finished_at":"2020-05-13T19:50:31.453Z","duration":4146.93611,"queued_duration":1.126974,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148001","artifacts":[{"file_type":"trace","size":283448,"filename":"job.log","file_format":null}],"runner":{"id":380987,"description":"shared-runners-manager-6.gitlab.com","ip_address":"34.74.239.13","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":"2020-05-20T19:50:29.755Z","tag_list":[]}
{"id":551148000,"status":"success","stage":"stage-1","name":"build:edge+flambda:dune:dev","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:21.523Z","started_at":"2020-05-13T18:41:24.347Z","finished_at":"2020-05-13T19:03:19.175Z","duration":1314.82792,"queued_duration":0.977569,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551148000","artifacts":[{"file_type":"trace","size":23727,"filename":"job.log","file_format":null}],"runner":{"id":44028,"description":"shared-runners-manager-3.gitlab.com","ip_address":"35.196.21.178","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":"2020-05-20T19:03:17.338Z","tag_list":[]}
{"id":551147999,"status":"success","stage":"stage-1","name":"build:edge+flambda","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:21.501Z","started_at":"2020-05-13T18:41:23.935Z","finished_at":"2020-05-13T19:11:12.457Z","duration":1788.521151,"queued_duration":0.591436,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551147999","artifacts":[{"file_type":"trace","size":283930,"filename":"job.log","file_format":null}],"runner":{"id":380986,"description":"shared-runners-manager-5.gitlab.com","ip_address":"34.74.209.140","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":"2020-05-20T19:11:09.949Z","tag_list":[]}
{"id":551147998,"status":"success","stage":"stage-1","name":"build:base+32bit","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:21.475Z","started_at":"2020-05-13T18:41:23.857Z","finished_at":"2020-05-13T18:58:10.574Z","duration":1006.717809,"queued_duration":0.532896,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551147998","artifacts":[{"file_type":"trace","size":277348,"filename":"job.log","file_format":null}],"runner":{"id":44949,"description":"shared-runners-manager-4.gitlab.com","ip_address":"13.37.237.197","active":true,"paused":false,"is_shared":true,"runner_type":"instance_type","name":"gitlab-runner","online":false,"status":"stale"},"artifacts_expire_at":"2020-05-20T18:58:08.935Z","tag_list":[]}
{"id":551147997,"status":"success","stage":"stage-1","name":"build:base","ref":"pr-12316","tag":false,"coverage":null,"allow_failure":false,"created_at":"2020-05-13T18:41:21.439Z","started_at":"2020-05-13T18:41:23.677Z","finished_at":"2020-05-13T18:51:53.359Z","duration":629.681483,"queued_duration":0.375526,"user":{"id":2256237,"username":"coqbot","name":"coqbot","state":"active","avatar_url":"https://gitlab.com/uploads/-/system/user/avatar/2256237/avatar.png","web_url":"https://gitlab.com/coqbot","created_at":"2018-04-28T07:53:57.210Z","bio":"Hello, I'm a bot.","location":"","public_email":"","skype":"","linkedin":"","twitter":"","website_url":"","organization":"","job_title":"","pronouns":null,"bot":false,"work_information":null,"followers":0,"following":0,"local_time":null},"commit":{"id":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","short_id":"f7e44f9e","created_at":"2020-05-13T14:39:56.000-04:00","parent_ids":["91b5990e724acc863a5dba66acc33fd698ac26f0"],"title":"Use pagination in fetching the number of reviews","message":"Use pagination in fetching the number of reviews\n\nFixes #12300\n\nNote that I currently only paginate the API call for the number of\nreviews, not the main API call, because (a) the main API call doesn't\nseem subject to pagination (it returns a dict, not an array), and (b)\nbecause fetching the total number of pages incurs an extra API call for\neach one that we want to paginate, even if there is only one page.  We\ncould work around (b) with a significantly more complicated\n`curl_paginate` function which heuristically recognizes the end of the\nheader/beginning of the body, such as\n```bash\ncurl_paginate() {\n  # as per https://developer.github.com/v3/guides/traversing-with-pagination/#changing-the-number-of-items-received, GitHub will never give us more than 100\n  url=\"$1?per_page=100\"\n  # We need to process the header to get the pagination.  We have two\n  # options:\n  #\n  # 1. We can make an extra API call at the beginning to get the total\n  #    number of pages, search for a rel=\"last\" link, and then loop\n  #    over all the pages.\n  #\n  # 2. We can ask for the header info with every single curl request,\n  #    search for a rel=\"next\" link to follow to the next page, and\n  #    then parse out the body from the header.\n  #\n  # Although (1) is simpler, we choose to do (2) to save an extra API\n  # call per invocation of curl.\n  while [ ! -z \"${url}\" ]; do\n    response=\"$(curl -si \"${url}\")\"\n    # we search for something like 'link: <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"next\", <https://api.github.com/repositories/1377159/pulls/12129/reviews?page=2>; rel=\"last\"' and take the first 'next' url\n    url=\"$(echo \"${response}\" | grep -m 1 -io '^link: .*>; rel=\"next\"' | grep -o '<[^>]*>; rel=\"next\"' | grep -o '<[^>]*>' | sed s'/[<>]//g')\"\n    echo \"Response: ${response}\" >&2\n    echo \"${response}\" |\n      {\n        is_header=\"yes\"\n        while read line; do\n          if [ \"${is_header}\" == \"yes\" ]; then\n            if echo \"${line}\" | grep -q '^\\s*[\\[{]'; then # we treat lines beginning with [ or { as the beginning of the response body\n              is_header=\"no\"\n              echo \"${line}\"\n            fi\n          else\n            echo \"${line}\"\n          fi\n        done\n      }\n  done\n}\n```\n","author_name":"Jason Gross","author_email":"jgross@mit.edu","authored_date":"2020-05-13T13:40:51.000-04:00","committer_name":"Jason Gross","committer_email":"jgross@mit.edu","committed_date":"2020-05-13T14:39:56.000-04:00","trailers":{},"web_url":"https://gitlab.com/coq/coq/-/commit/f7e44f9e3a7fe48608642f07c97e46dc528f8007"},"pipeline":{"id":145727264,"iid":16110,"project_id":6138686,"sha":"f7e44f9e3a7fe48608642f07c97e46dc528f8007","ref":"pr-12316","status":"failed","source":"push","created_at":"2020-05-13T18:41:21.392Z","updated_at":"2020-05-13T21:43:34.367Z","web_url":"https://gitlab.com/coq/coq/-/pipelines/145727264"},"web_url":"https://gitlab.com/coq/coq/-/jobs/551147997","artifacts":[{"file_type":"trace","size":500900,"filename":"job.log","file_format":null}],"runner":null,"artifacts_expire_at":"2020-05-20T18:51:51.638Z","tag_list":[]}
